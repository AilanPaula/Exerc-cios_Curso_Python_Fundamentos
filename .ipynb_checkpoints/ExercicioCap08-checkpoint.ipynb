{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício Cap08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 43.9 ms\n",
      "Wall time: 1.78 s\n"
     ]
    }
   ],
   "source": [
    "# Crie um array NumPy com 1000000 e uma lista com 1000000.\n",
    "# Multiplique cada elemento do array e da lista por 2 e calcule o tempo de execução com cada um dos objetos (use %time).\n",
    "# Qual objeto oferece melhor performance, array NumPy ou lista?\n",
    "import numpy as np\n",
    "\n",
    "ar = np.arange(1000000)\n",
    "lista = list(range(1000000))\n",
    "\n",
    "%time for c in range(10): ar2 = ar*2\n",
    "%time for c in range(10): lista2 = [x * 2 for x in lista]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 0 0 0 8 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercício 2\n",
    "# Crie um array de 10 elementos\n",
    "# Altere o valores de todos os elementos dos índices 5 a 8 para 0\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "ar = np.arange(10)\n",
    "\n",
    "ar[5:8] = 0\n",
    "\n",
    "print(ar)\n",
    "type(ar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crie um array de 3 dimensões e imprima a dimensão 1 \n",
    "import numpy as np\n",
    "ar = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n",
    "print(ar[0])\n",
    "type(ar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "# Crie um array de duas dimensões (matriz).\n",
    "# Imprima os elementos da terceira linha da matriz\n",
    "# Imprima todos os elementos da primeira e segunda linhas e segunda e terceira colunas\n",
    "\n",
    "import numpy as np\n",
    "ar = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "print(ar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(ar[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3]\n",
      " [5 6]]\n"
     ]
    }
   ],
   "source": [
    "print(ar[:2, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcule a transposta da matriz abaixo\n",
    "arr = np.arange(15).reshape((3, 5))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  5, 10],\n",
       "       [ 1,  6, 11],\n",
       "       [ 2,  7, 12],\n",
       "       [ 3,  8, 13],\n",
       "       [ 4,  9, 14]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1 2.1 True\n",
      "1.2 2.2 False\n",
      "1.3 2.3 True\n",
      "1.4 2.4 True\n",
      "1.5 2.5 False\n"
     ]
    }
   ],
   "source": [
    "# Considere os 3 arrays abaixo\n",
    "# Retorne o valor do array xarr se o valor for True no array cond. Caso contrário, retorne o valor do array yarr.\n",
    "xarr = np.array([1.1, 1.2, 1.3, 1.4, 1.5])\n",
    "yarr = np.array([2.1, 2.2, 2.3, 2.4, 2.5])\n",
    "cond = np.array([True, False, True, True, False])\n",
    "\n",
    "for x, y, c in zip(xarr, yarr, cond):\n",
    "    print(x, y, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1, 2.2, 1.3, 1.4, 2.5]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado = [(x if c else y) for x, y, c in zip(xarr, yarr, cond)]\n",
    "resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Crie um array A com 10 elementos e salve o array em disco com a extensão npy\n",
    "# Depois carregue o array do disco no array B\n",
    "\n",
    "A = np.arange(10)\n",
    "print(A)\n",
    "np.save('array_a', A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "B = np.load('array_a.npy')\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considerando a série abaixo, imprima os valores únicos na série\n",
    "import pandas as pd\n",
    "obj = pd.Series(['c', 'a', 'd', 'a', 'a', 'b', 'b', 'c', 'c', 'a', 'b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['c', 'a', 'd', 'b'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques = obj.unique()\n",
    "uniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Considerando o trecho de código que conecta em uma url na internet, imprima o dataframe conforme abaixo.\n",
    "import requests\n",
    "url = 'https://api.github.com/repos/pandas-dev/pandas/issues'\n",
    "resp = requests.get(url)\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'merge_ordered() should accept left_index and right_index args'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = resp.json()\n",
    "data[0]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>title</th>\n",
       "      <th>labels</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27760</td>\n",
       "      <td>merge_ordered() should accept left_index and r...</td>\n",
       "      <td>[]</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27758</td>\n",
       "      <td>Cannot plot empty Series</td>\n",
       "      <td>[]</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27756</td>\n",
       "      <td>Error reading parquet from s3 with s3fs &gt;= 0.3.0</td>\n",
       "      <td>[{'id': 2301354, 'node_id': 'MDU6TGFiZWwyMzAxM...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27755</td>\n",
       "      <td>Fix numpy boolean subtraction error in Series....</td>\n",
       "      <td>[]</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27750</td>\n",
       "      <td>Suppress UnicodeEncodeError when executing to_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27749</td>\n",
       "      <td>to_csv() and read_csv() do not preserve dtype ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27748</td>\n",
       "      <td>Reference docs: Nearly empty page for pandas.D...</td>\n",
       "      <td>[]</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27745</td>\n",
       "      <td>DEPR: remove alias of Categorical.take_nd to C...</td>\n",
       "      <td>[]</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27744</td>\n",
       "      <td>DEPR: remove Index._is_all_dates?</td>\n",
       "      <td>[]</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>27737</td>\n",
       "      <td>to_csv and read_csv return inconsistent result...</td>\n",
       "      <td>[]</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>27736</td>\n",
       "      <td>REF: pandas/core/window.py into multiple files</td>\n",
       "      <td>[{'id': 127681, 'node_id': 'MDU6TGFiZWwxMjc2OD...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>27733</td>\n",
       "      <td>BUG: fix to_datetime(dti, utc=True)</td>\n",
       "      <td>[{'id': 211840, 'node_id': 'MDU6TGFiZWwyMTE4ND...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>27732</td>\n",
       "      <td>TYPING: more type hints for io.common</td>\n",
       "      <td>[{'id': 1280988427, 'node_id': 'MDU6TGFiZWwxMj...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>27730</td>\n",
       "      <td>BUG: update dict of sheets before check</td>\n",
       "      <td>[{'id': 49254273, 'node_id': 'MDU6TGFiZWw0OTI1...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>27729</td>\n",
       "      <td>use DataFrame.style and can't get [cellstyle] ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>27722</td>\n",
       "      <td>What to use instead of pd.read_msgpack/df.to_m...</td>\n",
       "      <td>[]</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>27721</td>\n",
       "      <td>problem in groupby-rank w/ multindex column</td>\n",
       "      <td>[{'id': 233160, 'node_id': 'MDU6TGFiZWwyMzMxNj...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>27719</td>\n",
       "      <td>Removed continued parametrization of FilePathO...</td>\n",
       "      <td>[{'id': 1280988427, 'node_id': 'MDU6TGFiZWwxMj...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>27718</td>\n",
       "      <td>Set to_csv(index=False) by default</td>\n",
       "      <td>[]</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>27709</td>\n",
       "      <td>any/all reductions on boolean object-typed Series</td>\n",
       "      <td>[]</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>27696</td>\n",
       "      <td>Fix pandas replace does not work with boolean</td>\n",
       "      <td>[]</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>27692</td>\n",
       "      <td>Data types are not preserved while concatenati...</td>\n",
       "      <td>[{'id': 849023693, 'node_id': 'MDU6TGFiZWw4NDk...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>27686</td>\n",
       "      <td>dataframe.plot with secondary_y=True makes dif...</td>\n",
       "      <td>[{'id': 2413328, 'node_id': 'MDU6TGFiZWwyNDEzM...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>27684</td>\n",
       "      <td>`to_sql` does not correctly load data into sno...</td>\n",
       "      <td>[{'id': 47232590, 'node_id': 'MDU6TGFiZWw0NzIz...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>27682</td>\n",
       "      <td>ENH: Implement weighted rolling var and std</td>\n",
       "      <td>[{'id': 1045950827, 'node_id': 'MDU6TGFiZWwxMD...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27679</td>\n",
       "      <td>to_parquet swallows NoCredentialsError</td>\n",
       "      <td>[{'id': 685114413, 'node_id': 'MDU6TGFiZWw2ODU...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27678</td>\n",
       "      <td>Option to raise on dtype coercion in append / ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27677</td>\n",
       "      <td>BUG: fixes formatted value error for missing s...</td>\n",
       "      <td>[{'id': 42670965, 'node_id': 'MDU6TGFiZWw0MjY3...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>27676</td>\n",
       "      <td>read_excel: sheet_name of non-existent sheet d...</td>\n",
       "      <td>[{'id': 49254273, 'node_id': 'MDU6TGFiZWw0OTI1...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>27672</td>\n",
       "      <td>dataframe.fillna with df fails in a specific case</td>\n",
       "      <td>[{'id': 2822342, 'node_id': 'MDU6TGFiZWwyODIyM...</td>\n",
       "      <td>open</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number                                              title  \\\n",
       "0    27760  merge_ordered() should accept left_index and r...   \n",
       "1    27758                           Cannot plot empty Series   \n",
       "2    27756   Error reading parquet from s3 with s3fs >= 0.3.0   \n",
       "3    27755  Fix numpy boolean subtraction error in Series....   \n",
       "4    27750  Suppress UnicodeEncodeError when executing to_...   \n",
       "5    27749  to_csv() and read_csv() do not preserve dtype ...   \n",
       "6    27748  Reference docs: Nearly empty page for pandas.D...   \n",
       "7    27745  DEPR: remove alias of Categorical.take_nd to C...   \n",
       "8    27744                  DEPR: remove Index._is_all_dates?   \n",
       "9    27737  to_csv and read_csv return inconsistent result...   \n",
       "10   27736     REF: pandas/core/window.py into multiple files   \n",
       "11   27733                BUG: fix to_datetime(dti, utc=True)   \n",
       "12   27732              TYPING: more type hints for io.common   \n",
       "13   27730            BUG: update dict of sheets before check   \n",
       "14   27729  use DataFrame.style and can't get [cellstyle] ...   \n",
       "15   27722  What to use instead of pd.read_msgpack/df.to_m...   \n",
       "16   27721        problem in groupby-rank w/ multindex column   \n",
       "17   27719  Removed continued parametrization of FilePathO...   \n",
       "18   27718                 Set to_csv(index=False) by default   \n",
       "19   27709  any/all reductions on boolean object-typed Series   \n",
       "20   27696     Fix pandas replace does not work with boolean    \n",
       "21   27692  Data types are not preserved while concatenati...   \n",
       "22   27686  dataframe.plot with secondary_y=True makes dif...   \n",
       "23   27684  `to_sql` does not correctly load data into sno...   \n",
       "24   27682        ENH: Implement weighted rolling var and std   \n",
       "25   27679             to_parquet swallows NoCredentialsError   \n",
       "26   27678  Option to raise on dtype coercion in append / ...   \n",
       "27   27677  BUG: fixes formatted value error for missing s...   \n",
       "28   27676  read_excel: sheet_name of non-existent sheet d...   \n",
       "29   27672  dataframe.fillna with df fails in a specific case   \n",
       "\n",
       "                                               labels state  \n",
       "0                                                  []  open  \n",
       "1                                                  []  open  \n",
       "2   [{'id': 2301354, 'node_id': 'MDU6TGFiZWwyMzAxM...  open  \n",
       "3                                                  []  open  \n",
       "4                                                  []  open  \n",
       "5                                                  []  open  \n",
       "6                                                  []  open  \n",
       "7                                                  []  open  \n",
       "8                                                  []  open  \n",
       "9                                                  []  open  \n",
       "10  [{'id': 127681, 'node_id': 'MDU6TGFiZWwxMjc2OD...  open  \n",
       "11  [{'id': 211840, 'node_id': 'MDU6TGFiZWwyMTE4ND...  open  \n",
       "12  [{'id': 1280988427, 'node_id': 'MDU6TGFiZWwxMj...  open  \n",
       "13  [{'id': 49254273, 'node_id': 'MDU6TGFiZWw0OTI1...  open  \n",
       "14                                                 []  open  \n",
       "15                                                 []  open  \n",
       "16  [{'id': 233160, 'node_id': 'MDU6TGFiZWwyMzMxNj...  open  \n",
       "17  [{'id': 1280988427, 'node_id': 'MDU6TGFiZWwxMj...  open  \n",
       "18                                                 []  open  \n",
       "19                                                 []  open  \n",
       "20                                                 []  open  \n",
       "21  [{'id': 849023693, 'node_id': 'MDU6TGFiZWw4NDk...  open  \n",
       "22  [{'id': 2413328, 'node_id': 'MDU6TGFiZWwyNDEzM...  open  \n",
       "23  [{'id': 47232590, 'node_id': 'MDU6TGFiZWw0NzIz...  open  \n",
       "24  [{'id': 1045950827, 'node_id': 'MDU6TGFiZWwxMD...  open  \n",
       "25  [{'id': 685114413, 'node_id': 'MDU6TGFiZWw2ODU...  open  \n",
       "26                                                 []  open  \n",
       "27  [{'id': 42670965, 'node_id': 'MDU6TGFiZWw0MjY3...  open  \n",
       "28  [{'id': 49254273, 'node_id': 'MDU6TGFiZWw0OTI1...  open  \n",
       "29  [{'id': 2822342, 'node_id': 'MDU6TGFiZWwyODIyM...  open  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "issues = pd.DataFrame(data, columns=['number', 'title', 'labels', 'state'])\n",
    "issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie um banco de dados no SQLite, crie uma tabela, insira registros, \n",
    "# consulte a tabela e retorne os dados em dataframe do Pandas\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "query = \"\"\"\n",
    "CREATE TABLE TESTE\n",
    "(Cidade VARCHAR(20), \n",
    " Estado VARCHAR(20),\n",
    " taxa REAL,        \n",
    " Impostos INTEGER\n",
    ");\"\"\"\n",
    "con = sqlite3.connect('dsa.db')\n",
    "con.execute(query)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [('Natal', 'Rio Grande do Norte', 2.63, 8),\n",
    "        ('Recife', 'Pernambuco', 1.6, 2),\n",
    "        ('Londrina', 'Paraná', 0.9, 5)]\n",
    "stmt = \"INSERT INTO TESTE VALUES(?, ?, ?, ?)\"\n",
    "con.executemany(stmt, data)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Natal', 'Rio Grande do Norte', 2.63, 8),\n",
       " ('Recife', 'Pernambuco', 1.6, 2),\n",
       " ('Londrina', 'Paraná', 0.9, 5)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor = con.execute('select * from teste')\n",
    "rows = cursor.fetchall()\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cidade</th>\n",
       "      <th>Estado</th>\n",
       "      <th>taxa</th>\n",
       "      <th>Impostos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natal</td>\n",
       "      <td>Rio Grande do Norte</td>\n",
       "      <td>2.63</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recife</td>\n",
       "      <td>Pernambuco</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Londrina</td>\n",
       "      <td>Paraná</td>\n",
       "      <td>0.90</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cidade               Estado  taxa  Impostos\n",
       "0     Natal  Rio Grande do Norte  2.63         8\n",
       "1    Recife           Pernambuco  1.60         2\n",
       "2  Londrina               Paraná  0.90         5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.description\n",
    "pd.DataFrame(rows, columns=[x[0] for x in cursor.description])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
